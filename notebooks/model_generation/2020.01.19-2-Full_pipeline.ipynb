{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Full_pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Background:**\n",
    "\n",
    "**Purpose:**\n",
    "\n",
    "**Methods:**\n",
    ">1. Introduction\n",
    ">2. Inits\n",
    "\n",
    "**Conclusions:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_context(context='notebook', font_scale=1.5)\n",
    "\n",
    "import logging\n",
    "logging.basicConfig()\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "from sklearn.model_selection import train_test_split, ParameterGrid\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "import mlflow\n",
    "\n",
    "# Load my own custom module\n",
    "import data_loading\n",
    "import constants\n",
    "\n",
    "import imblearn\n",
    "import joblib\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "import sklearn.metrics as skl_metrics\n",
    "\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funcs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate model wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def holdout_test_wrapper(X, y, test_size=0.25):    \n",
    "    # Split into CV/test set using target class to stratify\n",
    "    X_train_untransformed, X_test_untransformed, y_train, y_test = train_test_split(X, \n",
    "                                                                                    y, \n",
    "                                                                                    test_size=test_size, \n",
    "                                                                                    stratify=y)\n",
    "    \n",
    "    return prediction_wrapper(X_train_untransformed, y_train, X_test_untransformed, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full prediction wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction_wrapper(X_train_untransformed, y_train, X_test_untransformed, y_test):\n",
    "    # Create the preprocessing pipeline\n",
    "    preprocessing_pipeline = Pipeline(steps = [('lower_quantile_cov_removal', remove_lower_CoV_quantiles(q=0.5))])\n",
    "\n",
    "    # Transform the data\n",
    "    X_train = preprocessing_pipeline.fit_transform(X_train_untransformed, y_train)\n",
    "    X_test = preprocessing_pipeline.transform(X_test_untransformed)\n",
    "\n",
    "    # Fit the model\n",
    "    log_regr_clf = train_subchallenge_1_model(X_train, y_train)\n",
    "    \n",
    "    y_train_pred = log_regr_clf.predict(X_train)\n",
    "    y_test_pred = log_regr_clf.predict(X_test)\n",
    "    \n",
    "    # Create an empty test results dict\n",
    "    results_dict = {}\n",
    "    \n",
    "    # Generate a confusion matrix\n",
    "    confusion_matrix = skl_metrics.confusion_matrix(y_true=y_test, y_pred=y_test_pred)\n",
    "    confusion_matrix_dict = {\n",
    "        'TP': confusion_matrix[1,1],\n",
    "        'TN': confusion_matrix[0,0],\n",
    "        'FP': confusion_matrix[0,1],\n",
    "        'FN': confusion_matrix[1,0]\n",
    "    }\n",
    "    \n",
    "    results_dict['confusion_matrix_dict'] = confusion_matrix_dict\n",
    "    \n",
    "    # Calculate train/test accuracy\n",
    "    results_dict['train_accuracy'] = np.mean(y_train_pred == y_train)\n",
    "    results_dict['test_accuracy'] = np.mean(y_test_pred == y_test)\n",
    "    \n",
    "    # Calculate the train/test AUC\n",
    "    train_fpr, train_tpr, _ = skl_metrics.roc_curve(y_true=y_train, \n",
    "                                                    y_score=log_regr_clf.predict_proba(X_train)[:, 1])\n",
    "    test_fpr, test_tpr, _ = skl_metrics.roc_curve(y_true=y_test, \n",
    "                                                  y_score=log_regr_clf.predict_proba(X_test)[:, 1])\n",
    "    \n",
    "    results_dict['train_auc'] = skl_metrics.auc(train_fpr, train_tpr)\n",
    "    results_dict['test_auc'] = skl_metrics.auc(test_fpr, test_tpr)\n",
    "\n",
    "    # Calculate the sensitivity and specificity\n",
    "    results_dict['test_sensitivity'],\\\n",
    "    results_dict['test_specificity'] = calculate_sens_and_spec(y_true=y_test, \n",
    "                                                               y_pred=y_test_pred)\n",
    "    \n",
    "    # Get the genes with non-zero coefficients\n",
    "    results_dict['non_zero_gene_list'] = X_train.columns[log_regr_clf.coef_[0] != 0]\n",
    "    \n",
    "    return results_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train sub-challenge 1 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_subchallenge_1_model(X_train, y_train):\n",
    "\n",
    "    # Define the model\n",
    "    log_regr_clf = LogisticRegression(penalty='l1',\n",
    "                                      C=0.129,\n",
    "#                                      random_state=110,\n",
    "                                      solver='saga',\n",
    "                                      max_iter=1e3,\n",
    "                                      verbose=0,\n",
    "                                      n_jobs=None,\n",
    "                                      l1_ratio=None)\n",
    "\n",
    "    # Run SMOTE on the X_train,y data\n",
    "    smote_obj = imblearn.over_sampling.SMOTE(sampling_strategy='auto', \n",
    "#                                             random_state=110, \n",
    "                                             k_neighbors=5, \n",
    "                                             n_jobs=None)\n",
    "    X_train_smote, y_train_smote = smote_obj.fit_sample(X_train, y_train)\n",
    "\n",
    "    # Train the model\n",
    "    log_regr_clf.fit(X_train_smote, y_train_smote)\n",
    "    \n",
    "    return log_regr_clf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove lower quantile of genes based on CoV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import FeatureUnion, Pipeline \n",
    "\n",
    "class remove_lower_CoV_quantiles(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, q):\n",
    "        self.q = q\n",
    "      \n",
    "    def fit(self, X, y = None):\n",
    "        # Calculate the CoV\n",
    "        gene_expr_cov_list = 100 * (X.std(ddof=1, axis=0) / X.mean(axis=0))\n",
    "\n",
    "        # Calculate the 0.9 quantile\n",
    "        min_cov_threshold = np.quantile(gene_expr_cov_list, q=[self.q])[0]\n",
    "\n",
    "        # Get a list of genes to removed\n",
    "        self.low_cov_gene_list = gene_expr_cov_list.loc[(gene_expr_cov_list < min_cov_threshold)].index.tolist()\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y = None):\n",
    "        return X.drop(self.low_cov_gene_list, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot ROC curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_roc_curve(fpr_list, tpr_list, label=''):\n",
    "    # Plot the ROC\n",
    "    plt.plot(fpr_list, tpr_list, label=f'{label} AUC={skl_metrics.auc(fpr_list, tpr_list):0.2f}')\n",
    "    plt.plot([0,1.0], [0.0, 1.0], 'k--', alpha=0.3)\n",
    "    \n",
    "    ax = plt.gca()\n",
    "    ax.legend()\n",
    "    ax.set_xlabel('False Positive Rate')\n",
    "    ax.set_ylabel('True Positive Rate')\n",
    "    \n",
    "    return ax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Sensitivity and Specificity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_sens_and_spec(y_true, y_pred):\n",
    "    # Generate a classification report dict\n",
    "    classification_report_dict = skl_metrics.classification_report(y_true,\n",
    "                                                                   y_pred,\n",
    "                                                                   output_dict=True)\n",
    "    # Get the sensitivity and specificity from the report dict\n",
    "    test_sensitivity = classification_report_dict['1']['recall']\n",
    "    test_specificity = classification_report_dict['0']['recall']\n",
    "\n",
    "    #print(f'sensitivity={test_sensitivity}, specificity: {test_specificity}')\n",
    "    \n",
    "    return test_sensitivity, test_specificity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sub-Challenge 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scratch Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Run the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Load the gene expression (GE) raw data from file\n",
    "X, y, phenotype_df = data_loading.load_sc1_data()\n",
    "\n",
    "# Split into CV/test set using target class to stratify\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Define the model\n",
    "log_regr_clf = LogisticRegression(penalty='l1',\n",
    "                                  C=1e-1,\n",
    "                                  random_state=110,\n",
    "                                  solver='saga',\n",
    "                                  max_iter=1e3,\n",
    "                                  verbose=0,\n",
    "                                  n_jobs=None,\n",
    "                                  l1_ratio=None)\n",
    "\n",
    "# Remove the lowest quartile of genes based on CoV\n",
    "# Calculate the CoV\n",
    "gene_expr_cov_list = 100 * (X_train.std(ddof=1, axis=0) / X_train.mean(axis=0))\n",
    "\n",
    "# Calculate the 0.9 quantile\n",
    "min_cov_threshold = np.quantile(gene_expr_cov_list, q=[0.9])[0]\n",
    "\n",
    "# Get a list of genes to removed\n",
    "low_cov_gene_list = gene_expr_cov_list.loc[(gene_expr_cov_list < min_cov_threshold)].index.tolist()\n",
    "\n",
    "# Remove the lowest 0.9 quantile of genes based on CoV\n",
    "X_train.drop(low_cov_gene_list, axis=1, inplace=True)\n",
    "X_test.drop(low_cov_gene_list, axis=1, inplace=True)\n",
    "\n",
    "# Run SMOTE on the X_train,y data\n",
    "smote_obj = imblearn.over_sampling.SMOTE(sampling_strategy='auto', \n",
    "                                         random_state=110, \n",
    "                                         k_neighbors=5, \n",
    "                                         n_jobs=None)\n",
    "X_train_smote, y_train_smote = smote_obj.fit_sample(X_train, y_train)\n",
    "\n",
    "# Train the model\n",
    "log_regr_clf.fit(X_train_smote, y_train_smote)\n",
    "\n",
    "# Predict the \n",
    "\n",
    "# Log sensitivity, specificity\n",
    "\n",
    "# Log AUC\n",
    "\n",
    "#mlflow.sklearn.log_model(svm_clf, \"model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Calculate AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Calculate the false positive rate and true positive rate\n",
    "train_fpr, train_tpr, _ = skl_metrics.roc_curve(y_true=y_train, y_score=log_regr_clf.predict_proba(X_train)[:, 1])\n",
    "test_fpr, test_tpr, _ = skl_metrics.roc_curve(y_true=y_test, y_score=log_regr_clf.predict_proba(X_test)[:, 1])\n",
    "\n",
    "plt.figure(figsize=(6,5))\n",
    "plt.plot(train_fpr, train_tpr, label=f'Train AUC={skl_metrics.auc(train_fpr, train_tpr):0.2f}')\n",
    "plt.plot(test_fpr, test_tpr, label=f'Test AUC={skl_metrics.auc(test_fpr, test_tpr):0.2f}')\n",
    "plt.plot([0,1.0], [0.0, 1.0], 'k--', alpha=0.3)\n",
    "\n",
    "ax = plt.gca()\n",
    "ax.legend()\n",
    "ax.set_xlabel('False Positive Rate')\n",
    "ax.set_ylabel('True Positive Rate')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Calculate Sensitivity/Specifity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "classification_report_dict = skl_metrics.classification_report(y_true=y_test,\n",
    "                                                               y_pred=log_regr_clf.predict(X_test),\n",
    "                                                               output_dict=True)\n",
    "\n",
    "test_sensitivity = classification_report_dict['1']['recall']\n",
    "test_specificity = classification_report_dict['0']['recall']\n",
    "\n",
    "print(f'sensitivity={test_sensitivity}, specificity: {test_specificity}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Final function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "calculate_sens_and_spec(y_true=y_test, \n",
    "                        y_pred=log_regr_clf.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final model code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Scratch code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Split into CV/test set using target class to stratify\n",
    "X_train_untransformed, X_test_untransformed, y_train, y_test = train_test_split(X, y, test_size=0.3, stratify=y)\n",
    "\n",
    "# Create the preprocessing pipeline\n",
    "preprocessing_pipeline = Pipeline(steps = [('lower_quantile_cov_removal', remove_lower_CoV_quantiles(q=0.5))])\n",
    "\n",
    "# Transform the data\n",
    "X_train = preprocessing_pipeline.fit_transform(X_train_untransformed, y_train)\n",
    "X_test = preprocessing_pipeline.transform(X_test_untransformed)\n",
    "\n",
    "# Fit the model\n",
    "log_regr_clf = train_subchallenge_1_model(X_train, y_train)\n",
    "\n",
    "train_fpr, train_tpr, _ = skl_metrics.roc_curve(y_true=y_train, y_score=log_regr_clf.predict_proba(X_train)[:, 1])\n",
    "test_fpr, test_tpr, _ = skl_metrics.roc_curve(y_true=y_test, y_score=log_regr_clf.predict_proba(X_test)[:, 1])\n",
    "\n",
    "# Calculate the train/test AUC\n",
    "train_auc = skl_metrics.auc(train_fpr, train_tpr)\n",
    "test_auc = skl_metrics.auc(test_fpr, test_tpr)\n",
    "\n",
    "# Calculate the sensitivity and specificity\n",
    "test_sens, test_spec = calculate_sens_and_spec(y_true=y_test, \n",
    "                                               y_pred=log_regr_clf.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the gene expression (GE) raw data from file\n",
    "X, y, phenotype_df = data_loading.load_sc1_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Running holdout tests in parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "holdout_test_results_list = joblib.Parallel(n_jobs=-1)\\\n",
    "    (joblib.delayed(holdout_test_wrapper)(X, y) for i in range(24*8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "test_auc_list = []\n",
    "test_sens_list = []\n",
    "test_spec_list = []\n",
    "for curr_holdout_results_dict in holdout_test_results_list:\n",
    "    test_auc_list.append(curr_holdout_results_dict['test_auc'])\n",
    "    test_sens_list.append(curr_holdout_results_dict['test_sensitivity'])\n",
    "    test_spec_list.append(curr_holdout_results_dict['test_specificity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "test_results_df = pd.DataFrame({'test_auc': test_auc_list,\n",
    "             'test_sens': test_sens_list,\n",
    "             'test_spec': test_spec_list})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "test_results_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running a single model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alex/miniconda3/envs/precfda_bc/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'confusion_matrix_dict': {'TP': 114, 'TN': 6, 'FP': 14, 'FN': 17},\n",
       " 'train_accuracy': 0.9203539823008849,\n",
       " 'test_accuracy': 0.7947019867549668,\n",
       " 'train_auc': 0.9771712158808933,\n",
       " 'test_auc': 0.5629770992366412,\n",
       " 'test_sensitivity': 0.8702290076335878,\n",
       " 'test_specificity': 0.3,\n",
       " 'non_zero_gene_list': Index(['ABCB1', 'ABCB7', 'ABHD2', 'ABI3BP', 'ACSBG1', 'ACSL1', 'ACSM5',\n",
       "        'ACTA1', 'ADAM1A', 'ADCY7',\n",
       "        ...\n",
       "        'ZNF544', 'ZNF566', 'ZNF594', 'ZNF649', 'ZNF665', 'ZNF721', 'ZNF738',\n",
       "        'ZNF785', 'ZNF880', 'ZNF883'],\n",
       "       dtype='object', length=884)}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "holdout_test_wrapper(X, y, test_size=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.12912192736135342"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "10**-0.889"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alex/miniconda3/envs/precfda_bc/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'confusion_matrix_dict': {'TP': 58, 'TN': 5, 'FP': 5, 'FN': 8},\n",
       " 'train_accuracy': 0.9269102990033222,\n",
       " 'test_accuracy': 0.8289473684210527,\n",
       " 'train_auc': 0.978142589118199,\n",
       " 'test_auc': 0.6984848484848485,\n",
       " 'test_sensitivity': 0.8787878787878788,\n",
       " 'test_specificity': 0.5,\n",
       " 'non_zero_gene_list': Index(['ABCA8', 'ABCB1', 'ABHD3', 'ABLIM3', 'ACBD5', 'ACO2', 'ACSBG1', 'ACSL3',\n",
       "        'ACSL6', 'ACSS1',\n",
       "        ...\n",
       "        'ZNF605', 'ZNF649', 'ZNF665', 'ZNF721', 'ZNF785', 'ZNF789', 'ZNF83',\n",
       "        'ZNF880', 'ZNF883', 'ZSWIM9'],\n",
       "       dtype='object', length=1004)}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "holdout_test_wrapper(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alex/miniconda3/envs/precfda_bc/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'confusion_matrix_dict': {'TP': 26, 'TN': 2, 'FP': 3, 'FN': 7},\n",
       " 'train_accuracy': 0.9380530973451328,\n",
       " 'test_accuracy': 0.7368421052631579,\n",
       " 'train_auc': 0.9761834100014839,\n",
       " 'test_auc': 0.5696969696969697,\n",
       " 'test_sensitivity': 0.7878787878787878,\n",
       " 'test_specificity': 0.4,\n",
       " 'non_zero_gene_list': Index(['AASS', 'ABCA5', 'ABCA6', 'ABCA7', 'ABCB1', 'ABCC8', 'ACAP3', 'ACKR3',\n",
       "        'ACSL1', 'ACTA1',\n",
       "        ...\n",
       "        'ZNF680', 'ZNF692', 'ZNF708', 'ZNF721', 'ZNF785', 'ZNF8', 'ZNF83',\n",
       "        'ZNF880', 'ZNF883', 'ZSWIM9'],\n",
       "       dtype='object', length=1154)}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "holdout_test_wrapper(X, y, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#del X_train\n",
    "#del X_train_untransformed\n",
    "del X_test\n",
    "#del X_test_untransformed\n",
    "#del y_train\n",
    "del y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alex/miniconda3/envs/precfda_bc/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.129, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=1000.0,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l1',\n",
       "                   random_state=None, solver='saga', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_regr_clf = LogisticRegression(penalty='l1',\n",
    "                                  C=0.129,\n",
    "#                                      random_state=110,\n",
    "                                  solver='saga',\n",
    "                                  max_iter=1e3,\n",
    "                                  verbose=0,\n",
    "                                  n_jobs=None,\n",
    "                                  l1_ratio=None)\n",
    "\n",
    "# Run SMOTE on the X_train,y data\n",
    "smote_obj = imblearn.over_sampling.SMOTE(sampling_strategy='auto', \n",
    "#                                             random_state=110, \n",
    "                                         k_neighbors=5, \n",
    "                                         n_jobs=None)\n",
    "X_train_smote, y_train_smote = smote_obj.fit_sample(X, y)\n",
    "\n",
    "# Train the model\n",
    "log_regr_clf.fit(X_train_smote, y_train_smote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['AAMDC', 'AASS', 'AATF', 'ABCA5', 'ABCA6', 'ABCA7', 'ABCA8', 'ABCB1',\n",
       "       'ABCC4', 'ABCC8',\n",
       "       ...\n",
       "       'ZNF738', 'ZNF768', 'ZNF785', 'ZNF789', 'ZNF808', 'ZNF83', 'ZNF880',\n",
       "       'ZNF883', 'ZSWIM7', 'ZSWIM9'],\n",
       "      dtype='object', length=1837)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.columns[log_regr_clf.coef_[0] != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
